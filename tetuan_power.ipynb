{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39383c3f-6534-4c3c-8083-c0d6b9581a3f",
   "metadata": {},
   "source": [
    "# Forecasting Daily Load Values in Tetouan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d242db6-2ad1-4df5-ba38-a521c95196a2",
   "metadata": {},
   "source": [
    "#### Goal\n",
    "Forecast the daily electricity consumption in Tetouan, Morocco."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95684bb-0816-4fd4-9780-24ef413d0df2",
   "metadata": {},
   "source": [
    "The data is a text file consisting of comma separated values, and can be found from UC Irvine's [Machine Learning Repository](https://archive.ics.uci.edu/dataset/849/power+consumption+of+tetouan+city).\n",
    "\n",
    "Each record contains 6 features and three targets:\n",
    " 1. [feature] Datetime\n",
    " 2. [feature] Temperature\n",
    " 3. [feature] Humidity\n",
    " 4. [feature] Wind Speed\n",
    " 5. [feature] General Diffuse Flows\n",
    " 6. [feature] Diffuse Flows\n",
    " 7. [target] Zone 1 Power Consumption\n",
    " 8. [target] Zone 2 Power Consumption\n",
    " 9. [target] Zone 3 Power Consumption\n",
    "\n",
    "There is a total of 52416 records. This represents 1 entire year of data, where the load values are sampled in 10 minute intervals. It is worth noting that Tetouan is a city in Morocco, so any modifications of the `DateTime` feature should take into account that Muslim countries do not have the same Sunda/Monday paradigm that Christian countries do, and that there is a different holiday schedule.\n",
    "\n",
    "Based on an entry in the [CoderzColumn](https://coderzcolumn.com/tutorials/artificial-intelligence/pytorch-lstm-networks-for-time-series-regression-tasks) Data Science / AI blog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49af94-2530-4ae6-b615-4f9f4fe2a8e6",
   "metadata": {},
   "source": [
    "#### Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c00734-aed0-48d4-b24e-5f39e3f434df",
   "metadata": {},
   "source": [
    "The forecasting approach will consist of applying a **Many-to-One Long-Short Term Memory (LSTM)** neural network, as implemented in the PyTorch module. The `many` refers to the fact that several features will be used when constructing the prediction of a `one` value, which in this case will be `Zone 1 Power Consumption`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726b2cb-d170-40e1-be67-30432ad1e1af",
   "metadata": {},
   "source": [
    "#### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afc802c-bd51-4446-8dae-a166cdfcee57",
   "metadata": {},
   "source": [
    "The LSTM block performs well detecting and forecasting the periodicity of the data. The performance on forecasting the absolute magnitures at the peaks and troughs is uniformly bad, however. This approach would not work for common load profile problems such as forecasting monthly peaks. In particular, the forecasted magnitudes in the trough regions are extremely bad, as they do not even capture the right curvature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197a95c1-9833-488d-a6a3-5e019864fc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import gc\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# ---------------------------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc4a4622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52416 entries, 0 to 52415\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   DateTime                   52416 non-null  object \n",
      " 1   Temperature                52416 non-null  float64\n",
      " 2   Humidity                   52416 non-null  float64\n",
      " 3   Wind Speed                 52416 non-null  float64\n",
      " 4   general diffuse flows      52416 non-null  float64\n",
      " 5   diffuse flows              52416 non-null  float64\n",
      " 6   Zone 1 Power Consumption   52416 non-null  float64\n",
      " 7   Zone 2  Power Consumption  52416 non-null  float64\n",
      " 8   Zone 3  Power Consumption  52416 non-null  float64\n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_orig = pd.read_csv(\"tetuan_power.csv\")\n",
    "df_orig.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282062ef",
   "metadata": {},
   "source": [
    "The main thing to note here is that there are no null entries in any of the data frame cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0e9ebc-f5c4-476a-a7ae-ee05bf5eccc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns : ['Temperature', 'Humidity', 'Wind Speed', 'general diffuse flows', 'diffuse flows', 'Zone 1 Power Consumption', 'Zone 2  Power Consumption', 'Zone 3  Power Consumption']\n",
      "Dataset Shape : (52416, 8)\n",
      "        Temperature      Humidity    Wind Speed  general diffuse flows  \\\n",
      "count  52416.000000  52416.000000  52416.000000           52416.000000   \n",
      "mean      18.810024     68.259518      1.959489             182.696614   \n",
      "std        5.815476     15.551177      2.348862             264.400960   \n",
      "min        3.247000     11.340000      0.050000               0.004000   \n",
      "25%       14.410000     58.310000      0.078000               0.062000   \n",
      "50%       18.780000     69.860000      0.086000               5.035500   \n",
      "75%       22.890000     81.400000      4.915000             319.600000   \n",
      "max       40.010000     94.800000      6.483000            1163.000000   \n",
      "\n",
      "       diffuse flows  Zone 1 Power Consumption  Zone 2  Power Consumption  \\\n",
      "count   52416.000000              52416.000000               52416.000000   \n",
      "mean       75.028022              32344.970564               21042.509082   \n",
      "std       124.210949               7130.562564                5201.465892   \n",
      "min         0.011000              13895.696200                8560.081466   \n",
      "25%         0.122000              26310.668692               16980.766032   \n",
      "50%         4.456000              32265.920340               20823.168405   \n",
      "75%       101.000000              37309.018185               24713.717520   \n",
      "max       936.000000              52204.395120               37408.860760   \n",
      "\n",
      "       Zone 3  Power Consumption  \n",
      "count               52416.000000  \n",
      "mean                17835.406218  \n",
      "std                  6622.165099  \n",
      "min                  5935.174070  \n",
      "25%                 13129.326630  \n",
      "50%                 16415.117470  \n",
      "75%                 21624.100420  \n",
      "max                 47598.326360  \n"
     ]
    }
   ],
   "source": [
    "data_df             = pd.read_csv(\"tetuan_power.csv\")\n",
    "data_df[\"DateTime\"] = pd.to_datetime(data_df[\"DateTime\"])\n",
    "data_df             = data_df.set_index('DateTime')\n",
    "data_df.columns     = [col.strip() for col in data_df.columns]\n",
    "print(\"Columns : {}\".format(data_df.columns.values.tolist()))\n",
    "print(\"Dataset Shape : {}\".format(data_df.shape))\n",
    "print(data_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534e76a0-3094-4be9-8797-d230fd1a4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.loc[\"2017-1\":\"2017-12\"].plot(\n",
    "    y=\"Zone 1 Power Consumption\",\n",
    "    figsize=(18, 7),\n",
    "    color=\"tomato\",\n",
    "    grid=True\n",
    ")\n",
    "plt.grid(\n",
    "    which=\"minor\", \n",
    "    linestyle=\":\", \n",
    "    linewidth=\"0.5\", \n",
    "    color=\"black\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2b5b0a-41f7-4202-83a3-5a7919ad2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.loc[\"2017-12-1\"].plot(\n",
    "    y=\"Zone 1 Power Consumption\", \n",
    "    figsize=(18, 7), \n",
    "    color=\"tomato\", \n",
    "    grid=True\n",
    ")\n",
    "plt.grid(\n",
    "    which=\"minor\", \n",
    "    linestyle=\":\", \n",
    "    linewidth=\"0.5\", \n",
    "    color=\"black\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b9dce-6644-4282-bb56-04af2e5524b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['Temperature', 'Humidity', 'Wind Speed', 'general diffuse flows', 'diffuse flows']\n",
    "target_col = 'Zone 1 Power Consumption'\n",
    "\n",
    "X = data_df[feature_cols].values\n",
    "Y = data_df[target_col].values\n",
    "\n",
    "n_features = X.shape[1]\n",
    "lookback = 30 ## 5 hours lookback to make prediction\n",
    "\n",
    "X_organized, Y_organized = [], []\n",
    "for i in range(0, X.shape[0]-lookback, 1):\n",
    "    X_organized.append(X[i:i+lookback])\n",
    "    Y_organized.append(Y[i+lookback])\n",
    "\n",
    "X_organized, Y_organized = np.array(X_organized), np.array(Y_organized)\n",
    "X_organized, Y_organized = torch.tensor(X_organized, dtype=torch.float32), torch.tensor(Y_organized, dtype=torch.float32)\n",
    "X_train, Y_train, X_test, Y_test = X_organized[:50000], Y_organized[:50000], X_organized[50000:], Y_organized[50000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa083a6f-3c72-4107-a290-43ca1eafc740",
   "metadata": {},
   "source": [
    "z-score normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97532aa5-1e7b-4d69-9762-cb38a12e187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = Y_train.mean(), Y_train.std()\n",
    "\n",
    "print(\"Mean : {:.2f}, Standard Deviation : {:.2f}\".format(mean, std))\n",
    "\n",
    "Y_train_scaled, Y_test_scaled = (Y_train - mean)/std , (Y_test-mean)/std\n",
    "\n",
    "print(Y_train_scaled.min())\n",
    "print(Y_train_scaled.max())\n",
    "print(Y_test_scaled.min())\n",
    "print(Y_test_scaled.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ce2550-b352-4798-8ae1-2cd531f5bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del X, Y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2c9965-86f9-403f-9202-5ab43689a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, Y_train_scaled)\n",
    "test_dataset  = TensorDataset(X_test,  Y_test_scaled)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=False, batch_size=32)\n",
    "test_loader  = DataLoader(test_dataset,  shuffle=False, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff38eb-1cb6-43d4-8e99-f54a572d4ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 128\n",
    "n_layers=2\n",
    "\n",
    "class LSTMRegressor(\n",
    "        nn.Module\n",
    "    ):\n",
    "    def __init__(self):\n",
    "        super(\n",
    "            LSTMRegressor,\n",
    "            self\n",
    "        ).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_features,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=n_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.linear = nn.Linear(\n",
    "            hidden_dim,\n",
    "            1\n",
    "        )\n",
    "    def forward(self, X_batch):\n",
    "        hidden, carry = torch.randn(\n",
    "            n_layers,\n",
    "            len(X_batch),\n",
    "            hidden_dim\n",
    "        ),\n",
    "        torch.randn(\n",
    "            n_layers,\n",
    "            len(X_batch),\n",
    "            hidden_dim\n",
    "        )\n",
    "        output, (hidden, carry) = self.lstm(X_batch, (hidden, carry))\n",
    "        return self.linear(output[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badd1645-540e-4510-aa39-a87029742920",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_regressor = LSTMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a2f18c-ea48-46a0-9e45-e127938d04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in lstm_regressor.children():\n",
    "    print(\"Layer : {}\".format(layer))\n",
    "    print(\"Parameters : \")\n",
    "    for param in layer.parameters():\n",
    "        print(param.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20bc077-fd6e-4da6-87ba-03af7c9beb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcValLoss(model, loss_fn, val_loader):\n",
    "    with torch.no_grad():\n",
    "        losses = []\n",
    "        for X, Y in val_loader:\n",
    "            preds = model(X)\n",
    "            loss = loss_fn(preds.ravel(), Y)\n",
    "            losses.append(loss.item())\n",
    "        print(\"Valid Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
    "\n",
    "def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=10):\n",
    "    for i in range(1, epochs+1):\n",
    "        losses = []\n",
    "        for X, Y in tqdm(train_loader):\n",
    "            Y_preds = model(X)\n",
    "\n",
    "            loss = loss_fn(Y_preds.ravel(), Y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
    "        CalcValLoss(model, loss_fn, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1092dca2-497d-4b43-a21a-6169b5c50c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "learning_rate = 1e-3\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "lstm_regressor = LSTMRegressor()\n",
    "optimizer = Adam(lstm_regressor.parameters(), lr=learning_rate)\n",
    "\n",
    "TrainModel(lstm_regressor, loss_fn, optimizer, train_loader, test_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6de6e6a-2433-4eb1-9ad2-b9433da45341",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = lstm_regressor(X_test) ## Make Predictions on test dataset\n",
    "test_preds  = (test_preds*std) + mean\n",
    "\n",
    "test_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da4523-58dd-486c-a19b-d466f725642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Test  MSE : {:.2f}\".format(mean_squared_error(test_preds.detach().numpy().squeeze(),Y_test.detach().numpy()))\n",
    ")\n",
    "print(\n",
    "    \"Test  R^2 Score : {:.2f}\".format(r2_score(test_preds.detach().numpy().squeeze(), Y_test.detach().numpy()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24c2d74-cd99-40ec-906c-5672cedc491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_final = data_df[50000:].copy()\n",
    "\n",
    "data_df_final[\"Zone 1 Power Consumption Prediction\"] = [None]*lookback + test_preds.detach().numpy().squeeze().tolist()\n",
    "\n",
    "data_df_final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde5498c-7d29-496b-8e0d-4916ef4fbe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_final.plot(\n",
    "    y=[\"Zone 1 Power Consumption\", \"Zone 1 Power Consumption Prediction\"],\n",
    "    figsize=(18,7)\n",
    ")\n",
    "plt.grid(\n",
    "    which='minor',\n",
    "    linestyle=':',\n",
    "    linewidth='0.5',\n",
    "    color='black'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b407ca41-1f0c-4e9e-be8a-07ab69b18c05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
