{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2483ccf7-d698-4a6c-b033-3a5c5c9e1f41",
   "metadata": {},
   "source": [
    "## Heart Stroke Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ccd32f-a641-4526-b10a-2cc3a40106d6",
   "metadata": {},
   "source": [
    "### 0. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe12366-632f-46b8-98a0-fa036aa900ed",
   "metadata": {},
   "source": [
    "#### Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9795b5-2a30-4cd5-81b2-c67d4a253a62",
   "metadata": {},
   "source": [
    "Forecast the likelihood of a patient experiencing a stroke as a function of:\n",
    " - presence of diseases,\n",
    " - age,\n",
    " - gender,\n",
    " - smoking status,\n",
    " - etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1734fa3-a57a-49e2-b76b-cd2c0f5836bb",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c01d3c-1a6e-4063-9cc7-8a31ff9a31f5",
   "metadata": {},
   "source": [
    "The data is a standard text file consisting of comma separated values, found in various places (for example [here](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset)), with the following features:\n",
    " 1. gender (object)\n",
    " 2. age (float)\n",
    " 3. hypertension (int)\n",
    " 4. heart_disease (int)\n",
    " 5. ever_married (object)\n",
    " 6. work_type (object)\n",
    " 7. Residence_type (object)\n",
    " 8. avg_glucose (float)\n",
    " 9. bmi (float)\n",
    " 10. smoking_status (object)\n",
    " 11. stroke (int)\n",
    "\n",
    "There is a total of 5110 records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e0758f-e707-4c1d-98ac-eb5d602ba818",
   "metadata": {},
   "source": [
    "#### Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e41e0c1-d1ee-47de-a7ab-e30ca0072464",
   "metadata": {},
   "source": [
    "Four methods will be used in attempting to forecast heart strokes:\n",
    " 1. Logistic Regression\n",
    " 2. Support Vector Machines\n",
    " 3. Decision Tree Classifiers\n",
    " 4. K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c295a149-e7f7-4d60-8b13-87fd552dc46f",
   "metadata": {},
   "source": [
    "---\n",
    "### 6. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfc81dc-dcb9-4f07-b484-c4d67ed0b340",
   "metadata": {},
   "source": [
    "#### Preprocess data for feature selection and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb618e0-b351-4dd1-b096-b8c18029e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import statsmodels.api as smapi\n",
    "import statsmodels as sms\n",
    "import scipy as scp\n",
    "import imblearn as imbl\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96aefff7-bb30-4660-a002-59586eb79741",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_kde(\n",
    "        df_input: pd.DataFrame,\n",
    "        grid_len: int,\n",
    "        lim_x: list[int],\n",
    "        lim_y: list[int],\n",
    "        data_spread: list[float],\n",
    "        lbl_mean: list[float],\n",
    "        lbl_median: list[float],\n",
    "        title: str,\n",
    "        ylabl: str,\n",
    "        xlabl: str,\n",
    "    ):\n",
    " \n",
    "    data_kde = df_input.to_numpy()\n",
    "    grid_kde = np.linspace(lim_x[0],lim_x[1],grid_len)\n",
    "    dens_kde = scp.stats.gaussian_kde(data_kde)(grid_kde)\n",
    "    val_mean = np.mean(data_kde)\n",
    "    val_medn = np.median(data_kde)\n",
    " \n",
    "    fig, axs = plt.subplots(figsize=(6,3))\n",
    "    axs.plot(grid_kde,dens_kde,color='blue',lw=1,linestyle='-')\n",
    "    axs.plot(data_kde,data_spread[0]+data_spread[1]*np.random.random(data_kde.shape[0]),'.',color='darkgray',alpha=0.1)\n",
    "    axs.axvline(ymin=0.000,ymax=1.000,x=np.mean(data_kde),  lw=0.5,color='red', label='mean')\n",
    "    axs.axvline(ymin=0.000,ymax=1.000,x=np.median(data_kde),lw=0.5,color='blue',label='median')\n",
    "    axs.tick_params(axis='both',direction='in',top=True,right=True)\n",
    "    axs.set_ylim(lim_y[0],lim_y[1])\n",
    "    axs.set_ylabel(ylabl)\n",
    "    axs.set_xlabel(xlabl)\n",
    "    axs.set_title(title)\n",
    "    axs.text(val_mean+lbl_mean[0],lbl_mean[1],f'mean={val_mean:.1f}')\n",
    "    axs.text(val_medn+lbl_median[0],lbl_median[1],f'median={val_medn:.1f}')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ae9fc6a-4621-43a5-9e87-da6856a7bdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 5110 non-null   int64  \n",
      " 1   gender             5110 non-null   object \n",
      " 2   age                5110 non-null   float64\n",
      " 3   hypertension       5110 non-null   int64  \n",
      " 4   heart_disease      5110 non-null   int64  \n",
      " 5   ever_married       5110 non-null   object \n",
      " 6   work_type          5110 non-null   object \n",
      " 7   Residence_type     5110 non-null   object \n",
      " 8   avg_glucose_level  5110 non-null   float64\n",
      " 9   bmi                4909 non-null   float64\n",
      " 10  smoking_status     5110 non-null   object \n",
      " 11  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 479.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# 0. read the dataframe\n",
    "df_orig = pd.read_csv(\"heart_stroke_prediction.csv\")\n",
    "df_orig.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77f57318-7b1a-4b39-b096-9c7b47d0dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. drop id column, save it for later\n",
    "df_id = df_orig['id'].copy()\n",
    "del df_orig['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c0487ed-2071-4216-8f24-96f4a6b17699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male' 'Female' 'Other']\n",
      "['Yes' 'No']\n",
      "['Private' 'Self-employed' 'Govt_job' 'children' 'Never_worked']\n",
      "['Urban' 'Rural']\n",
      "['formerly smoked' 'never smoked' 'smokes' 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "# 2. inspect unique values in each categorical feature\n",
    "for col in df_orig.columns:\n",
    "    if df_orig[col].dtype == 'object':\n",
    "        print(df_orig[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58a0263d-8a88-4465-9830-2c9f71acc0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. replace spaces and dashes with underscores\n",
    "for col in df_orig.columns:\n",
    "    if df_orig[col].dtype == 'object':\n",
    "        df_orig[col] = df_orig[col].str.replace('-','_')\n",
    "        df_orig[col] = df_orig[col].str.replace(' ','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d6eefd6-e509-4a9d-993d-d63196cbe1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. turn all string-typed categorical values to lower-case\n",
    "for col in df_orig.columns:\n",
    "    if df_orig[col].dtype == 'object':\n",
    "        df_orig[col] = df_orig[col].map(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e3ce3d0-54d2-49eb-8d64-bcd4cc79dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. change all column titles to lower case\n",
    "df_orig.columns = df_orig.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1bccfe6-e56a-4a43-bc35-422a7de31a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gender             5110 non-null   object \n",
      " 1   age                5110 non-null   float64\n",
      " 2   hypertension       5110 non-null   int64  \n",
      " 3   heart_disease      5110 non-null   int64  \n",
      " 4   ever_married       5110 non-null   object \n",
      " 5   work_type          5110 non-null   object \n",
      " 6   residence_type     5110 non-null   object \n",
      " 7   avg_glucose_level  5110 non-null   float64\n",
      " 8   bmi                4909 non-null   float64\n",
      " 9   smoking_status     5110 non-null   object \n",
      " 10  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(3), object(5)\n",
      "memory usage: 439.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# 6. take a look at some details.\n",
    "df_orig.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce52e86-63b2-437a-97f7-b7612c2a28aa",
   "metadata": {},
   "source": [
    "The numerical `bmi` feature is missing about 4% of the values. These will be imputed at a later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "261be8b9-1eec-4c34-b7e8-cd7ecc820acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "201 201\n",
      "0 0\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "# 7. look for isna values\n",
    "for col in df_orig.columns:\n",
    "    print(df_orig[col].isna().sum(),df_orig[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4cc29c-792e-4bc2-9bcc-39e3763da8d0",
   "metadata": {},
   "source": [
    "This confirms the output of the previous `df.info()` step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6531ccc6-9da7-4a60-8d2b-c735e70568e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. rename all columns to 3 letters - messy looking code wastes time. Don't change 'stroke'\n",
    "df_orig = df_orig.rename(columns={\n",
    "        'gender'           :'gen',\n",
    "        'hypertension'     :'hyp',\n",
    "        'heart_disease'    :'htd',\n",
    "        'ever_married'     :'evm',\n",
    "        'work_type'        :'wtp',\n",
    "        'residence_type'   :'rtp',\n",
    "        'avg_glucose_level':'agl',\n",
    "        'smoking_status'   :'sms',\n",
    "    }   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865d6b70-b0de-43f8-a53b-04f64ff85879",
   "metadata": {},
   "source": [
    "#### Use K-Nearest Neighbors to impute the missing `bmi` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f06c15da-f678-456a-9633-fd76a560c2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. section out the different types found in the dataframe\n",
    "feat_obj = df_orig.select_dtypes(include='object' ).columns.values.tolist()\n",
    "feat_int = df_orig.select_dtypes(include='int64'  ).columns.values.tolist()\n",
    "feat_flt = df_orig.select_dtypes(include='float64').columns.values.tolist()\n",
    "feat_tgt = [feat_int.pop(feat_int.index('stroke'))] # the target feature is int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e601eb0-4621-4a57-9b3d-afe684a1c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. label-encode categorical (object) columns\n",
    "encoders = {}\n",
    "df_prep  = pd.DataFrame()\n",
    "for col in feat_obj:\n",
    "    encoders[col]   = skl.preprocessing.LabelEncoder()\n",
    "    curr_data       = df_orig[col][df_orig[col].notnull()].values.reshape(-1,1)\n",
    "    encoders[col].fit(curr_data)\n",
    "    df_prep[col]    = encoders[col].transform(curr_data).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144384e3-e97d-4be1-bae7-8f24ed0d42ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. add the rest of the features to df_work, convert everything to floats\n",
    "df_prep = pd.concat([df_prep, df_orig[feat_int],df_orig[feat_flt],df_orig[feat_tgt]],axis=1,join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6832b083-fb9a-456f-9cd5-ea260a1c2498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. impute NaN values via KNN - all ints cast as floats here\n",
    "df_impt = pd.DataFrame(\n",
    "    skl.impute.KNNImputer(n_neighbors=11).fit_transform(df_prep),\n",
    "    columns=df_prep.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c82775-5d0a-4032-bb80-795ea44cf82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. change obj & int features back to int64. rename column\n",
    "df_impt[feat_obj+feat_int+feat_tgt] = df_impt[feat_obj+feat_int+feat_tgt].astype(int)\n",
    "df_trgt = df_impt[feat_tgt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f56c88a-8142-42a8-9e78-172ef9cd4c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. decode the imputed columns back to their original categories\n",
    "for key, val in encoders.items():\n",
    "    reshaped_col = df_impt[key].values.reshape(-1,1)\n",
    "    df_impt[key] = encoders[key].inverse_transform(reshaped_col).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7457ce-b3f2-4f36-8d39-a9359e33a017",
   "metadata": {},
   "source": [
    "#### Encode Categorical Features: One-Hot & Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79a78a3e-b2c7-4e86-9d17-f16a5ed0ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot encode all the categorical types\n",
    "encoder_onehot = skl.preprocessing.OneHotEncoder(sparse_output=False)\n",
    "data_encd = encoder_onehot.fit_transform(df_impt[feat_obj]) # encoder is saved for later.\n",
    "df_encd = pd.DataFrame(data_encd,columns=encoder_onehot.get_feature_names_out())\n",
    "# the feat_obj columns are already label encoded, so just concatenate\n",
    "#df_encd = pd.concat([df_encd, df_impt[feat_obj]], axis=1, join='outer')\n",
    "#df_encd = df_encd.astype(float) # change the feat_obj cols from int to floats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7aebff-828b-47fd-96a2-4db776526386",
   "metadata": {},
   "source": [
    "#### Generate Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6996b218-e1e6-4e87-9b5a-a98de4eb5c17",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def feature_numerical(\n",
    "        data_col: pd.DataFrame(), # type: ignore\n",
    "        transforms: list[str],\n",
    "    ):\n",
    "    data_transformed = []\n",
    "    for xfr in transforms:\n",
    "        if xfr == 'logexp':\n",
    "            data = np.log(data_col)\n",
    "            data.name = data_col.name + '_logexp'\n",
    "            data_transformed.append(data)\n",
    "        elif xfr == 'logten':\n",
    "            data = np.log10(data_col)\n",
    "            data.name = data_col.name + '_logten'\n",
    "            data_transformed.append(data)\n",
    "        elif xfr == 'boxcox':\n",
    "            data = pd.Series(scp.stats.boxcox(data_col)[0])\n",
    "            data.name = data_col.name + '_boxcox'\n",
    "            data_transformed.append(data)\n",
    "        elif xfr == 'yeojon':\n",
    "            data = pd.Series(scp.stats.yeojohnson(data_col)[0])\n",
    "            data.name = data_col.name + '_yeojon'\n",
    "            data_transformed.append(data)\n",
    "        elif xfr == 'power2':\n",
    "            data = np.power(data_col,2)\n",
    "            data.name = data_col.name + '_power2'\n",
    "            data_transformed.append(data)\n",
    "        elif xfr == 'power3':\n",
    "            data = np.power(data_col,3)\n",
    "            data.name = data_col.name + '_power3'\n",
    "            data_transformed.append(data)\n",
    "    dataframe = pd.concat(data_transformed, axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adc0911-f9fd-4ed8-9cc9-949fb2298e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate numerical features - add to these if needed (these should be enough)\n",
    "transformations = ['logexp','logten','boxcox','yeojon','power2','power3']\n",
    "df_flts = pd.DataFrame() # \"dataframe floats\"\n",
    "df_flts = pd.concat([\n",
    "        df_flts,\n",
    "        feature_numerical(df_impt['bmi'],transformations),\n",
    "        feature_numerical(df_impt['age'],transformations),\n",
    "        feature_numerical(df_impt['agl'],transformations),\n",
    "    ],\n",
    "    axis=1,\n",
    "    join='outer'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ada970-9aec-4bf6-8f78-217aaa4a510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Robust Scaling - best overall performance for irregularly shaped distros\n",
    "df_scld = pd.DataFrame()\n",
    "for col in df_flts:\n",
    "    temp_col = df_flts[col].values.reshape(-1, 1)\n",
    "    df_scld[col] = skl.preprocessing.RobustScaler().fit_transform(temp_col).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63afaad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a 6x3 grid of seaborn kernel density estimators of all the rescaled features\n",
    "fig, axs = plt.subplots(6,3,figsize=(9,9))\n",
    "for i, col in enumerate(df_scld.columns):\n",
    "    sns.kdeplot(\n",
    "        data=df_scld[col],\n",
    "        ax=axs[i//3,i%3],\n",
    "        color='blue',\n",
    "        lw=1,\n",
    "        linestyle='-'\n",
    "    )\n",
    "    axs[i//3,i%3].set_title(col)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3affa0",
   "metadata": {},
   "source": [
    "#### Preliminary test on the Feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7efe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_work = pd.DataFrame()\n",
    "df_work = pd.concat([df_work, df_encd, df_scld], axis=1, join='outer')\n",
    "df_work.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86153885",
   "metadata": {},
   "source": [
    "We are now working with the following 4 data-frames:\n",
    "1. df_encd: one-hot encoded categorical features\n",
    "2. df_scld: Robust-scaled transformed numerical features\n",
    "3. df_trgt: The target feature (stroke)\n",
    "4. df_work: df_encd + df_scld.\n",
    "\n",
    "The main working data frame, `df_work` contains 33 features. The next steps consist of getting first an idea of whether this set can produce a sufficiently high *f1-score*, followed by feature-pruning to increase the density of the data points in the feature-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1e3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no corrections for imbalanced data \n",
    "class_lr = skl.linear_model.LogisticRegressionCV(cv=5,random_state=42,max_iter=1000)\n",
    "class_lr.fit(df_work, df_trgt.values.flatten())\n",
    "y_pred = class_lr.predict(df_work)\n",
    "print(skl.metrics.classification_report(df_trgt,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d9e61b",
   "metadata": {},
   "source": [
    "The support values are substantially imbalanced (4861 vs. 249), and the *f1-score* reflects these levels of support. Add SMOTEENN preprocessing with minority sampling strategy to compensate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40030351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced data - minority class oversampled\n",
    "# ----------------------------------------------------------------------------------\n",
    "# preprocess dataframes with oversampling\n",
    "smoteenn = imbl.combine.SMOTEENN(random_state=42,sampling_strategy='minority')\n",
    "df_work_res, df_trgt_res = smoteenn.fit_resample(df_work, df_trgt)\n",
    "# ----------------------------------------------------------------------------------\n",
    "# same logistic regression as before\n",
    "class_lr = skl.linear_model.LogisticRegressionCV(cv=5,random_state=42,max_iter=1000)\n",
    "class_lr.fit(df_work_res, df_trgt_res.values.flatten())\n",
    "y_pred = class_lr.predict(df_work_res)\n",
    "print(skl.metrics.classification_report(df_trgt_res,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476314b7",
   "metadata": {},
   "source": [
    "As noted in the EDA performed in a separate notebook, the categorical features are all quite imbalanced, and applying SMOTEENN therefore achieves significant improvements in predicting both stroke & no-stroke in patients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bc23c4",
   "metadata": {},
   "source": [
    "#### Statistical tests: Numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88105ea",
   "metadata": {},
   "source": [
    "Each numerical feature can be mapped on to an incidence of stroke in the patients. Taken in the aggregate, these will form 2 sets that are distributed in some manner. Comparing these 2 sets with each other, via independent sample tests, provides us with an understanding of their contribution to the effectiveness of the ensuing regression algorithms. So, features will be rejected on the basis of whether or not the *alternate hypothesis (H1)* is accepted in each independent sample test.\n",
    "* `scipy.stats.ttest_ind`: t-test for independence\n",
    "    * H0: populations have the same means, differences are due to random error in sampling\n",
    "    * H1: populations do not have the same means, differences are NOT due to random sampling errors\n",
    "    * p_value: if < 0.05 accept H1, else accept H0. If H0 is accepted, remove feature from set.\n",
    "* `scipy.stats.mannwhitneyu`: Mann-Whitney U\n",
    "    * H0: populations have identical distribution\n",
    "    * H1: populations do not have an identical distribution\n",
    "    * p_value: if < 0.05 accept H1, else accept H0. If H0 is accepted, remove feature from set.\n",
    "* `scipy.stats.bws_test`: Baumgartner-Weiss-Schindler\n",
    "    * H0: populations have same underlying probability distribution\n",
    "    * H1: populations do not have same underlying probability distribution\n",
    "    * p_value: if < 0.05 accept H1, else accept H0. If H0 is accepted, remove feature from set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some tests \n",
    "sample_tests_num = {}\n",
    "categories = df_trgt['stroke'].unique()\n",
    "for ii, col in enumerate(df_scld.columns):\n",
    "    grp_1 = df_work[df_trgt['stroke'] == categories[0]][col]\n",
    "    grp_2 = df_work[df_trgt['stroke'] == categories[1]][col]\n",
    "    sample_tests_num[col] = {\n",
    "        't_test_ind'    : (scp.stats.ttest_ind   (grp_1, grp_2, alternative='two-sided')),\n",
    "        'mann_whitney_u': (scp.stats.mannwhitneyu(grp_1, grp_2, alternative='two-sided')),\n",
    "        'bws_test'      : (scp.stats.ttest_ind   (grp_1, grp_2, alternative='two-sided')),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e03f8",
   "metadata": {},
   "source": [
    "#### Statistical tests: Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34053711",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii, col in enumerate(df_encd.columns):\n",
    "    print(ii, df_encd[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62657c52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
